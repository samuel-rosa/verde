# Resgate de Dados do Solo {#resgate-de-dados}

_Alessandro Samuel-Rosa_[^alessandro], _Marcos Alexandre dos Anjos_[^marcos-alexandre]

```{r, echo = FALSE, include = FALSE}
knitr::read_chunk("resgate-de-dados-do-solo.R")
```

<!-- O Capítulo \@ref(#resgate-de-dados) discutirá sobre a maneira mais eficiente de indicar a origem dos dados em casos como esse. -->

Muitos dados estão "presos" em documentos no formato PDF.
Mesmo sendo um formato de arquivo de texto popular, o formato PDF acaba dando muita dor de cabeça para quem quer reutilizar os dados.
Os arquivos PDF são ótimos para visualização por humanos.
Mas quando precisamos editar ou automatizar o processo de extração das informações contidas neles, geralmente temos um grande problema em mãos.

A estratégia mais comum para resgatar dados de arquivos PDF é a utilização do recurso familiar `Ctrl + C` e `Ctrl + V`, quando selecionamos a área desejada para ser copiada que, depois, é colada em um arquivo de texto ou planilha eletrônica.
Isso costuma requerer bastante pós-processamento dos dados e geralmente produz alguns problemas.
Por exemplo, união de dados de duas ou mais colunas, dados de uma linha acabam indo para outra linha, símbolos que não são reconhecidos, ou mesmo esquecimento de copiar um ou mais dados.
Podemos corrigir manualmente esses problemas, ou mesmo digitar grande parte dos dados.
Mas isso geralmente tomará muito tempo e será pouco eficiente!

## Programas de computador

Uma solução mais recente são os programas de computador de extração de dados de documentos PDF.
Existem algumas alternativas para libertar os dados tabulares presos dentro dos PDFs.
Alguns exemplos mais populares são [Tabula][tabula], [Rows][rows] e [PDFtables][pdftables].

Cada software citado tem o mesmo objetivo em comum: reconhecimento e extração de dados tabulares.
No caso do Rows e PDFtables, o processo é realizado por linha de comando, o que torna impossível selecionar um parte específica de interesse da tabela.
Já no Tabula, temos a liberdade de selecionar somente uma parte de uma tabela, se esse for o interesse.

Infelizmente, nenhum dos softwares existentes hoje reconhecem todos os padrão de estruturas de tabelas existentes em documentos PDF.
Isso é especialmente importante no caso dos dados do solo contidos em documentos PDF: cada trabalho costuma estruturar os dados de maneira diferente, inclusive usando nomenclaturas diferentes.
Isso significa que a extração de dados do solo de documentos PDF pode ser apenas parcialmente automatizada, necessitando sempre de alguma intervenção manual para garantir sua integridade.

[rows]: https://github.com/turicas/rows
[pdftables]: https://pdftables.com/pdf-to-excel-api

## Tabula

O [Tabula][tabula] é um software livre e de código aberto desenvolvido na linguagem [Java][java].
Ele pode ser utilizado em sistemas operacionais Linux, Windows e MacOS, sem a necessidade de instalação.
Basta descarregar o arquivo executável indicado para o sistema operacional do computador em que será empregado.
Uma vez executado, o Tabula inicializa como aplicação no navegador da Internet utilizando o endereço local http://127.0.0.1:8080.
Isso significa que todo o processo de extração dos dados dos arquivos PDF é realizado localmente, sem necessidade de conexão à Internet.

[tabula]: https://tabula.technology/
[java]: https://pt.wikipedia.org/wiki/Java_(linguagem_de_programa%C3%A7%C3%A3o)

A extração de dados de um documento PDF inicia pela importação do arquivo para o Tabula.
Quanto menor o arquivo, mais rápida será sua importação e a extração dos dados.
Por isso, é mais prudente importar apenas as páginas de onde serão extraídos os dados.

Uma vez importado o arquivo PDF, faz-se a seleção da área contendo os dados a serem extraídos (Figura \@ref(fig:tabula-selecao-dos-dados)).
Isso pode ser feito demarcando a área com o _mouse_ ou usando a opção _Autodetect tables_.
Contudo, a opção de auto detecção geralmente exige ajustes manuais.
Isso é especialmente importante quando o cabeçalho das colunas contém células mescladas.
A presença de tais células dificulta a identificação das colunas.
Elas resultam na fusão indevida das colunas inferiores quando os dados são extraídos pelo Tabula.
Por essa razão, recomenda-se que o cabeçalhos das colunas seja ignorado e resgatado manualmente em etapa posterior.

```{r, tabula-selecao-dos-dados, echo = FALSE, fig.cap = "Seleção da área para extração de dados."}
```

A próxima etapa consiste em analisar se os dados foram extraídos corretamente.
Algumas vezes é necessário retornar à etapa anterior para revisar a área selecionada para extração dos dados.
Caso a área selecionada esteja correta, pode ser necessário escolher outro método de extração dos dados.
O Tabula dispõe de dois métodos para tentar recriar a estrutura de uma tabela de dados.
O método _lattice_ utiliza a localização das linhas divisórias entre as colunas, razão pela qual costuma produzir muitos erros quando há células mescladas.
Já o método _stream_ contabiliza os espaços em branco entre as colunas, o que o torna eficiente na extração de dados estruturas não tabulares como listas.

```{r, tabula-visualizacao-dos-dados-extraidos, echo = FALSE, fig.cap = "Visualização preliminar dos dados extraídos."}
```

Dados extraídos pelo Tabula podem ser exportados para formatos de arquivo de texto delimitado como [CSV][csv] e [TSV][tsv].
Esses arquivos podem ser importados para qualquer editor de planilhas eletrônicas como  Microsoft Excel, Google Sheets ou LibreOffice Calc.
Isso facilita a realização de quaisquer ajuste necessários nos dados.
Por exemplo, o Tabula criou uma coluna adicional na segunda tabela de dados.
Isso ocorreu devido à estratégia usada pelos autores do trabalho para apresentar os dados da soma dos elementos Ca^2+^ e Mg^2+^ no horizonte Cg (Figura \@ref(fig:tabula-inconsistencia-nos-dados)).

```{r, tabula-inconsistencia-nos-dados, echo = FALSE, fig.cap = "Razão da inconsistência na extração dos dados."}
```

[csv]: https://pt.wikipedia.org/wiki/Comma-separated_values
[tsv]: https://www.reviversoft.com/pt/file-extensions/tsv

Para analisar a eficiência do Tabula, nós extraímos os dados das 267 amostras extra contidas no documento PDF do trabalho Solos do Estado de Santa Catarina (ctb0572).
Ao todo, a extração dos dados e pós-processamento, tomaram cerca de cinco horas: três horas para a extração e duas horas para o pós-processamento.
A extração envolveu a organização do arquivo PDF e a seleção da área de extração dos dados.
O pós-processamento envolveu a união dos dados das diferentes tabelas, a correção de inconsistências, e a formatação dos dados segundo os padrões do FEBR.
O exercício mostrou que o Tabula acelera o processo de extração de dados de documentos PDF.
Contudo, como a organização dos dados nesses documentos é pensada para leitura por humanos, o Tabula não será totalmente eficiente.
Algum pós-processamento manual sempre será necessário, mas isso geralmente será bastante fácil de fazer.
